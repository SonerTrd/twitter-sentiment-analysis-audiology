{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f3980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soner Türüdü\n",
    "# University of Groningen / UMCG\n",
    "# PhD Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dda147",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install tweepy\n",
    "!pip install tqdm\n",
    "\n",
    "!pip install wordcloud\n",
    "!pip install TurkishStemmer\n",
    "!pip install sklearn\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeafa81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter API\n",
    "import tweepy\n",
    "\n",
    "# Data Manipulation\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Bert Model\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "\n",
    "# Metin Ön İşleme\n",
    "from TurkishStemmer import TurkishStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c410538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API için Keyler\n",
    "# API link: https://developer.twitter.com/en/apps\n",
    "\n",
    "consumer_key = 'UV4Ez2JST8WoidziIlpUGQ5jQ'\n",
    "consumer_secret = 'kjCo7RU2gPIBAFwovxL4DjZAVx1aFcXhqnVJc37cVcP8Fv2pAH' \n",
    "access_token = '701828766-zz2kzacKDdLYrZdXpHqianWTrj6HsIDmhTRC7MtD'\n",
    "access_token_secret ='LGpUzvGrxUPgW6Z9xWWOBHYBGgXWACTukuTQ9Iua3eRdW'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0238940",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list = []\n",
    "text_query = 'odyologhaklari'\n",
    "count = 100\n",
    "\n",
    "for tweet in api.search_tweets(q=text_query, count=count, lang='tr-tr'):\n",
    "    tweets_list.append((tweet.created_at,tweet.id,tweet.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cbf2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame(tweets_list, columns=[\"Tarih\",'Tweet_id','Text'])\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a58ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"savasy/bert-base-turkish-sentiment-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"savasy/bert-base-turkish-sentiment-cased\")\n",
    "\n",
    "sentiment_analysis_pipeline= pipeline(\"sentiment-analysis\", tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae5ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis_pipeline(\"odyologhaklari\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad1c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_result=[]\n",
    "for text in tqdm(tweets.Text):\n",
    "    result = sentiment_analysis_pipeline(text)[0]\n",
    "    sentiment_result.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531061d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_result = pd.DataFrame(sentiment_result)\n",
    "sentiment_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbe7d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_result = pd.DataFrame(sentiment_result)\n",
    "tweets = pd.concat([tweets, sentiment_result],axis=1)\n",
    "tweets.label = tweets.label.map({'positive':1,'negative':0})\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a027de7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hepsini bir araya getiriyoruz\n",
    "class TwitterSentimentAnalyser:\n",
    "    def __init__(self, consumer_key, consumer_secret, access_token, access_token_secret, keyword, tweetCount):\n",
    "        self.keyword = keyword\n",
    "        self.consumer_key = consumer_key\n",
    "        self.consumer_secret = consumer_secret\n",
    "        self.access_token = access_token\n",
    "        self.access_token_secret = access_token_secret\n",
    "        self.tweetCount = tweetCount\n",
    "        \n",
    "    def getTwitterData(self):\n",
    "        tweets_list = []\n",
    "        \n",
    "        for tweet in api.search_tweets(q=self.keyword, count=self.tweetCount, lang='tr-tr'):\n",
    "            tweets_list.append((tweet.created_at,tweet.id,tweet.text))\n",
    "            \n",
    "        self.tweets = pd.DataFrame(tweets_list, columns=[\"Tarih\",'Tweet_id','Text'])\n",
    "            \n",
    "    def bertPipeline(self):\n",
    "        # Eğitilmiş Ağırlıkların Yüklenmesi\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\"savasy/bert-base-turkish-sentiment-cased\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"savasy/bert-base-turkish-sentiment-cased\")\n",
    "\n",
    "        self.sentiment_analysis_pipeline= pipeline(\"sentiment-analysis\", tokenizer=tokenizer, model=model)\n",
    "        \n",
    "    def sentimentPrediction(self):\n",
    "        self.sentiment_result=[]\n",
    "        for text in tqdm(self.tweets.Text):\n",
    "            result = sentiment_analysis_pipeline(text)[0]\n",
    "            self.sentiment_result.append(result)\n",
    "        \n",
    "        self.sentiment_result = pd.DataFrame(self.sentiment_result)\n",
    "        self.tweets = pd.concat([self.tweets, self.sentiment_result],axis=1)\n",
    "        self.tweets.label = self.tweets.label.map({'positive':1,'negative':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1908f50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "twst = TwitterSentimentAnalyser(consumer_key = consumer_key, consumer_secret = consumer_secret,\n",
    "                                access_token = access_token, access_token_secret = access_token_secret,\n",
    "                                keyword='odyologhaklari', tweetCount=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "twst.getTwitterData()\n",
    "twst.tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d898ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "twst.bertPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106e76e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "twst.sentimentPrediction()\n",
    "twst.tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991860fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{twst.keyword} hakkinda {twst.tweets.Tarih.min} ile {twst.tweets.Tarih.max} arasinda atilan {len(twst.tweets)} adet Tweet'in Pozitiflik orani {twst.tweets.label.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca401979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gorsellestirme\n",
    "labels = twst.tweets.label.map({1:'Positive',0:'Negative'}).value_counts().index.values\n",
    "sizes = twst.tweets.label.value_counts().values\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5432d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = twst.tweets.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f254b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64452994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verilerin temizlenmesi\n",
    "def preProcess(ReviewText):\n",
    "    #Verideki <br> taglarını kaldır.\n",
    "    ReviewText = ReviewText.str.lower()\n",
    "    ReviewText = ReviewText.str.replace(\"(<br/>)\", \"\")\n",
    "    ReviewText = ReviewText.str.replace('(<a).*(>).*(</a>)', '')\n",
    "    ReviewText = ReviewText.str.replace('(&amp)', '')\n",
    "    ReviewText = ReviewText.str.replace('(&gt)', '')\n",
    "    ReviewText = ReviewText.str.replace('(&lt)', '')\n",
    "    ReviewText = ReviewText.str.replace('(\\xa0)', ' ') \n",
    "    #Verideki Linkleri Kaldır.\n",
    "    ReviewText = ReviewText.str.replace(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', ' ') \n",
    "    return ReviewText\n",
    "\n",
    "data['Text'] = preProcess(data['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea94ca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kök Bulma\n",
    "stemmer = TurkishStemmer()\n",
    "\n",
    "stemmed_lists = []\n",
    "for index in tqdm(data.index):\n",
    "    mini_l = []\n",
    "    for text in data.loc[index]['Text'].split(\" \"):\n",
    "        mini_l.append(stemmer.stem(text))\n",
    "\n",
    "    big_text=\" \"\n",
    "    for char in mini_l:\n",
    "        big_text = big_text + \" \" + char\n",
    "    stemmed_lists.append(big_text)\n",
    "    \n",
    "data['stemmed'] = stemmed_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7734737",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac91a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gorsellestirme\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb78eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gorsellestirme\n",
    "common_words = get_top_n_words(data['Text'], 25)\n",
    "df2 = pd.DataFrame(common_words, columns = ['kelime' , 'geçiş frekansı'])\n",
    "fig = plt.figure(figsize=[25,5])\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(df2.kelime,df2['geçiş frekansı'])\n",
    "plt.title('Kök Bulmadan En Çok Geçen Kelimeler')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "common_words = get_top_n_words(data['stemmed'], 25)\n",
    "df2 = pd.DataFrame(common_words, columns = ['kelime' , 'geçiş frekansı'])\n",
    "fig = plt.figure(figsize=[25,5])\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(df2.kelime,df2['geçiş frekansı'])\n",
    "plt.title('Kök Bulduktan sonra En Çok Geçen Kelimeler')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e7d91f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
